[tool.poetry]
name = "experiment-backend"
version = "0.1.0"
description = "backend experiment project"
authors = ["tkosht"]
license = "MIT"
readme = "README.md"
packages = [{include = "app"}]


[tool.poetry.dependencies]
python = ">=3.10, <3.12"        # <3.12 for sktime


# for data science
numpy = "*"
pandas = "*"
fireducks = "*"
dask = {extras = ["complete"], version = "*"}
scikit-learn = "*"
scipy = "*"
mlxtend = "*"
sympy = "*"
tqdm = "*"
matplotlib = "*"
seaborn = "*"
plotly = "*"
pandasgui = "*"
pandas-profiling = "*"
pygwalker = "*"
scikit-optimize = "*"
optuna = "*"
memory_profiler = "*"
lime = "*"
shap = "*"
# pyyaml = "5.3.1"
pyyaml = "*"

PyQt5 = "=5.15.2"
lit = "^17.0.2"
ipynb = "*"

# for experiment management
mlflow = "*"
tensorboard = "*"
tensorboardX = "*"
# python-dateutil==2.8.0
hydra-core = "*"
sqlite-web = "*"
evidently = "*"

# crawler
scrapy = "*"
selenium = "*"
webdriver_manager = "*"
retry = "*"
firecrawl-py = "*"
# unstructured = "*"
unstructured = {extras = ["pdf"], version = "*"}
pymupdf4llm = "*"


# Database
# psycopg2 = "*"
psycopg2-binary = "*"

# other tools
omegaconf = "*"
notebook = "*"
python-dotenv = "*"
ulid-py = "*"
typer = "*"
simplejson = "*"


# # for project
fastapi = "*"
uvicorn = "*"
# aiofiles = "*"
# python-multipart = "*"

# for being faster torch dependency resolving
# torch = {url = "https://download.pytorch.org/whl/cu118/torch-2.2.2%2Bcu118-cp310-cp310-linux_x86_64.whl"}
# # for installing vllm
torch = {url = "https://download.pytorch.org/whl/cu118/torch-2.1.2%2Bcu118-cp310-cp310-linux_x86_64.whl"}
# torchvision = "*"
# torchvision = {url = "https://download.pytorch.org/whl/cu118/torch-2.2.2%2Bcu118-cp310-cp310-linux_x86_64.whl"}

# torchmetrics = "*"
# nltk = "*"
# torchtext = "*"
# pytorch-forecasting = "*"
tensorflow-datasets = "*"

# python-snappy = "*"
# pyro-ppl = "*"
# pystan = "2.19.1.1"
# pystan = "*"
prophet = "*"
ruptures = "*"
neo4j = "*"
neomodel = "*"
networkx-neo4j = "*"

# # for NLP
unidic-lite = "*"
sudachidict_core = "*"
sudachidict_small = "*"
sudachidict_full = "*"
# spacy = "*"
# spacy = {extras = ["cuda110"], version = "*"}
# spacy-transformers = "1.1.3"
# ja_ginza_electra = "*"
# fugashi = "*"
# ipadic = "*"
# networkx = "*"
gensim = "*"
janome = "*"
mecab-python3 = "*"
sentencepiece = "*"
einops = "*"
# wordcloud = "*"

# transformers = "*"
# git+https://github.com/huggingface/transformers
# transformers = {git = "https://github.com/huggingface/transformers"}
# transformers = "^4.43.1"
transformers = "*"
datasets = "^2.15.0"

# LLM relatives
# # for langchain
numexpr = "*"
langchain = "^0.0.354"
langchain-experimental = "*"
langgraph="*"
langchain_openai = "*"
tavily-python = "*"
openai = "*"
# open-interpreter = "*"
google-search-results = "*"
google-api-python-client = "*"
google-generativeai = "*"
langchain-google-genai = "*"
pillow = "*"
chromadb = "*"
tiktoken = "*"
sentence_transformers = "*"
faiss-gpu = "*"
trafilatura = "*"
llama-index = "*"
llama-index-embeddings-huggingface = "*"
llama-index-embeddings-langchain = "*"
llama-index-llms-anthropic = "*"
llama-index-readers-notion = "*"
llama-index-packs-sentence-window-retriever = "*"
llama-index-vector-stores-faiss = "*"
llama-index-postprocessor-rankgpt-rerank = "*"


dify-client = "*"
promptflow = "*"
promptflow-tools = "*"
ragas = "*"
langsmith = "*"
langfuse = "*"


# PDF
pymupdf = "*"
pypdf = "*"
cryptography = "*"
# pdfminer.six = "*"
# pycryptodome = "*"
# pandas_datareader = "*"
azure-ai-documentintelligence = "*"


wikipedia = "*"
# Flask-Cors = "*"

# guidance
guidance = "*"

# Semantic Kernel
semantic-kernel = "*"

# for LLM
huggingface_hub = "*"
codeboxapi = "*"
llama-cpp-python = "*"
# vllm = "*"
# Install vLLM with CUDA 11.8.
vllm = {url="https://github.com/vllm-project/vllm/releases/download/v0.4.0/vllm-0.4.0+cu118-cp310-cp310-manylinux1_x86_64.whl"}
# heron = {git = "https://github.com/turingmotors/heron.git"}


# for elyza/ELYZA-japanese-Llama-2-7b-instruct
# transformers
# datasets
# mecab-python3
# unidic-lite
# sentencepiece
accelerate = "*"
bitsandbytes = "*"
pynvml = "*"
deepspeed = "*"
mpi4py = "*"
peft = "*"
trl = "*"
gguf = "^0.1.0"
exllamav2 = "*"
fastparquet = "*"

# webapp
# gradio = "^3.21.0"
gradio = "*"
# streamlit = "^1.24.0"
streamlit = "*"
streamlit-chat = "*"
streamlit-extras = "*"
streamsync = {extras = ["ds"], version = "*"}
hugchat = "*"

# datascience
lightgbm = "*"
dtw-python = "^1.3.0"
llvmlite = "^0.40.1"
numba = "^0.57.1"
tslearn = "^0.6.1"
sktime = "^0.21.0"
# protobuf = "3.20.1"
protobuf = "^4.24.2"
jupyter-kernel-gateway = "^2.5.2"
statsmodels = "^0.14.0"
yfinance = "^0.2.28"
pingouin = "^0.5.3"


[tool.poetry.dev-dependencies]
# for sqa
pudb = "*"
pylint = "*"
flake8 = "*"
black = "*"
coverage = "*"
pytest = "*"
pytest-flake8 = "*"
pytest-cov = "*"
pytest-xdist = "*"
pytest-html = "*"
# docutils==0.15
Sphinx = "*"


[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

