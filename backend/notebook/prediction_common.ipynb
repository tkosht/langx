{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy\n",
    "import pandas\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "def set_seeds(seed: int):\n",
    "    assert seed > 0\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    numpy.random.seed(seed)\n",
    "\n",
    "\n",
    "set_seeds(seed=42)\n",
    "\n",
    "sns.set_theme(font=\"IPAexGothic\", font_scale=2)\n",
    "\n",
    "pyplot.rcParams[\"figure.figsize\"] = (20, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation\n",
    "from prophet.diagnostics import performance_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prophet_model(is_longterm=True, **params) -> Prophet:\n",
    "   print(f\"build_prophet_model: {is_longterm=} {params}\")\n",
    "   model = Prophet(**params, yearly_seasonality=4)\n",
    "   model.add_seasonality(name='triennial', period=365.25*3, fourier_order=1)\n",
    "   model.add_seasonality(name='kitchen', period=365.25/12*40, fourier_order=1)\n",
    "   if is_longterm:\n",
    "      model.add_seasonality(name='quinquennial', period=365.25*5, fourier_order=1)\n",
    "      model.add_seasonality(name='decennial_09', period=365.25*9, fourier_order=1)\n",
    "      model.add_seasonality(name='decennial_10', period=365.25*10, fourier_order=1)\n",
    "   return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator(object):\n",
    "   def __init__(self, df: pandas.DataFrame, n_horizon: int=365.25, freq=\"3MS\", horizon_scaler: float =3) -> None:\n",
    "      self.df: pandas.DataFrame = df\n",
    "      self.n_horizon: int = n_horizon  # cv prediction range\n",
    "      self.freq = freq     # cutoff freq\n",
    "      self.horizon_scaler = horizon_scaler\n",
    "      self.max_changepoints = self.df.shape[0]\n",
    "\n",
    "   def objective_value(self, trial: optuna.Trial) -> float:\n",
    "      params = {\n",
    "               \"growth\" : \n",
    "                  trial.suggest_categorical(\"growth\", [\"linear\", \"logistic\"]),\n",
    "               \"changepoint_range\" : \n",
    "                  trial.suggest_float(\"changepoint_range\", 0.8, 1.0),\n",
    "               \"n_changepoints\" : \n",
    "                  trial.suggest_int(\"n_changepoints\", 1, self.max_changepoints),\n",
    "               \"changepoint_prior_scale\" : \n",
    "                  trial.suggest_float(\"changepoint_prior_scale\", 0.001, 5),\n",
    "               \"seasonality_prior_scale\" : \n",
    "                  trial.suggest_float(\"seasonality_prior_scale\", 0.01, 10),\n",
    "               \"seasonality_mode\" : \n",
    "                  trial.suggest_categorical(\"seasonality_mode\", [\"additive\", \"multiplicative\"])\n",
    "               }\n",
    "\n",
    "      model: Prophet = build_prophet_model(**params)\n",
    "      model.fit(self.df)\n",
    "      __df_cv, df_pm = self.run_cross_validation(model=model)\n",
    "      n = df_pm.shape[0]\n",
    "      # NOTE: \n",
    "      #     - rmse: horizon が長くなる(index が後になる)とエラー幅が増加するので、\n",
    "      #             差に敏感な rmse の後半を多めに評価するように逆順で累積する\n",
    "      #     - mae : rmse と同じく、horizon が短い間も精度が高くないと困るので、\n",
    "      #             前半を多めに評価するように mae を累積する\n",
    "      score = numpy.cumsum(df_pm['rmse'].values[::-1]).mean() + numpy.cumsum(df_pm['mae'].values).mean()\n",
    "      score /= n     # for intepretability of `score` in optuna.visualizaion\n",
    "\n",
    "      return score\n",
    "\n",
    "   def run_cross_validation(self, model: Prophet) -> tuple[pandas.DataFrame, pandas.DataFrame]:\n",
    "      n_horizon = self.n_horizon\n",
    "      date_start = self.df.ds.max() - pandas.Timedelta(days=n_horizon * self.horizon_scaler)\n",
    "      date_end = self.df.ds.max() - pandas.Timedelta(days=n_horizon)\n",
    "      cutoffs = pandas.date_range(start=date_start, end=date_end, freq=self.freq)\n",
    "\n",
    "      # run cv and metrics\n",
    "      df_cv = cross_validation(model, cutoffs=cutoffs, horizon=f\"{n_horizon} days\", parallel=\"processes\")\n",
    "      df_pm = performance_metrics(df_cv)\n",
    "\n",
    "      # store context\n",
    "      self.date_start = date_start\n",
    "      self.date_end = date_end\n",
    "      self.cutoffs = cutoffs\n",
    "\n",
    "      return df_cv, df_pm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Limitter(object):\n",
    "    df: pandas.DataFrame\n",
    "\n",
    "    def __post_init__(self):\n",
    "        df = self.df\n",
    "        self.floor = df.y.min() - 3 * df.y.std()\n",
    "        self.cap = df.y.max() + 3 * df.y.std()\n",
    "\n",
    "\n",
    "def setup_limit(df: pandas.DataFrame, lmt: Limitter, inplace=False) -> pandas.DataFrame:\n",
    "    _df = df\n",
    "    if not inplace:\n",
    "        _df = df.copy()\n",
    "    _df[\"floor\"] = lmt.floor\n",
    "    _df[\"cap\"] = lmt.cap\n",
    "    return _df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BestEstimator(object):\n",
    "    df: pandas.DataFrame\n",
    "    model: Prophet\n",
    "    evaluator: Evaluator\n",
    "    study: optuna.Study\n",
    "    df_cv: dict\n",
    "    df_pm: dict\n",
    "    future: pandas.DataFrame | None = None\n",
    "    forecast: pandas.DataFrame | None = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_df_index(df: pandas.DataFrame, col=\"ds\", do_drop: bool=True):\n",
    "    df.index = df[col]\n",
    "    if do_drop:\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_wareki_to_seireki(wareki_date):\n",
    "    \"\"\"\n",
    "    和暦を西暦に変換する関数。\n",
    "    \"\"\"\n",
    "    era = wareki_date[0]\n",
    "    year, month, day = map(int, wareki_date[1:].split('.'))\n",
    "\n",
    "    if era == \"S\":  # 昭和\n",
    "        seireki_year = 1925 + year\n",
    "    elif era == \"H\":  # 平成\n",
    "        seireki_year = 1988 + year\n",
    "    elif era == \"R\":  # 令和\n",
    "        seireki_year = 2018 + year\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown era: {era}\")\n",
    "\n",
    "    return f\"{seireki_year}-{month:02}-{day:02}\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
