{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-20 15:04:45,421] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79bdef7ed2e54f179e7136a58d53c494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/355 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713b247de337471e8d207554c526e944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c3672e453743f6a91ad8a4cdb3c0a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataset = load_dataset(\"takaaki-inada/databricks-dolly-15k-ja-zundamon\", split=\"train\")\n",
    "dataset = load_dataset(\"kunishou/databricks-dolly-15k-ja\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>index</th>\n",
       "      <th>instruction</th>\n",
       "      <th>category</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ヴァージン・オーストラリア航空（Virgin Australia Airlines Pty ...</td>\n",
       "      <td>0</td>\n",
       "      <td>ヴァージン・オーストラリア航空はいつから運航を開始したのですか？</td>\n",
       "      <td>closed_qa</td>\n",
       "      <td>ヴァージン・オーストラリア航空は、2000年8月31日にヴァージン・ブルー航空として、2機の...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>魚の種類はどっち？イコクエイラクブカとロープ</td>\n",
       "      <td>classification</td>\n",
       "      <td>イコクエイラクブカ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>ラクダはなぜ水なしで長く生きられるのか？</td>\n",
       "      <td>open_qa</td>\n",
       "      <td>ラクダは、長時間にわたってエネルギーと水分で満たされた状態を保つために、腰の脂肪を利用しています。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>アリスの両親には3人の娘がいる：エイミー、ジェシー、そして三女の名前は？</td>\n",
       "      <td>open_qa</td>\n",
       "      <td>三女の名前はアリス</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>小森田は1981年7月10日、熊本県に生まれる。高校卒業後、2000年にJ1リーグのアビスパ...</td>\n",
       "      <td>4</td>\n",
       "      <td>小森田友明はいつ生まれたの？</td>\n",
       "      <td>closed_qa</td>\n",
       "      <td>小森田友明は1981年7月10日に生まれました。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15010</th>\n",
       "      <td></td>\n",
       "      <td>15010</td>\n",
       "      <td>変更を受け入れるにはどうしたらよいですか</td>\n",
       "      <td>brainstorming</td>\n",
       "      <td>変化を受け入れて、違いを見る</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15011</th>\n",
       "      <td>レーザーは、電磁波の誘導放出に基づく光増幅の過程で光を放出する装置である。レーザーという言葉...</td>\n",
       "      <td>15011</td>\n",
       "      <td>レーザーとは何か、誰が作ったのか？</td>\n",
       "      <td>summarization</td>\n",
       "      <td>レーザーは、電磁波源から光を放出する装置である。  最初のレーザーは、チャールズ・H・タウン...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15012</th>\n",
       "      <td></td>\n",
       "      <td>15012</td>\n",
       "      <td>ロードバイクとマウンテンバイクの違いは何ですか？</td>\n",
       "      <td>open_qa</td>\n",
       "      <td>ロードバイクはアスファルトやセメントの上を走ることを想定して作られており、細いタイヤが装着さ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15013</th>\n",
       "      <td></td>\n",
       "      <td>15013</td>\n",
       "      <td>不動産投資業界において、GISはどのように役立っているのでしょうか。</td>\n",
       "      <td>general_qa</td>\n",
       "      <td>不動産投資家は、ビジネスを展開する市場や場所に関する競争力を高めるために、正確で精度の高いロ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15014</th>\n",
       "      <td></td>\n",
       "      <td>15014</td>\n",
       "      <td>マスターズとは？</td>\n",
       "      <td>general_qa</td>\n",
       "      <td>マスターズ・トーナメントは、毎年4月の第1週にジョージア州オーガスタのオーガスタ・ナショナル...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15015 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   input  index  \\\n",
       "0      ヴァージン・オーストラリア航空（Virgin Australia Airlines Pty ...      0   \n",
       "1                                                             1   \n",
       "2                                                             2   \n",
       "3                                                             3   \n",
       "4      小森田は1981年7月10日、熊本県に生まれる。高校卒業後、2000年にJ1リーグのアビスパ...      4   \n",
       "...                                                  ...    ...   \n",
       "15010                                                     15010   \n",
       "15011  レーザーは、電磁波の誘導放出に基づく光増幅の過程で光を放出する装置である。レーザーという言葉...  15011   \n",
       "15012                                                     15012   \n",
       "15013                                                     15013   \n",
       "15014                                                     15014   \n",
       "\n",
       "                                instruction        category  \\\n",
       "0          ヴァージン・オーストラリア航空はいつから運航を開始したのですか？       closed_qa   \n",
       "1                    魚の種類はどっち？イコクエイラクブカとロープ  classification   \n",
       "2                      ラクダはなぜ水なしで長く生きられるのか？         open_qa   \n",
       "3      アリスの両親には3人の娘がいる：エイミー、ジェシー、そして三女の名前は？         open_qa   \n",
       "4                            小森田友明はいつ生まれたの？       closed_qa   \n",
       "...                                     ...             ...   \n",
       "15010                  変更を受け入れるにはどうしたらよいですか   brainstorming   \n",
       "15011                     レーザーとは何か、誰が作ったのか？   summarization   \n",
       "15012              ロードバイクとマウンテンバイクの違いは何ですか？         open_qa   \n",
       "15013    不動産投資業界において、GISはどのように役立っているのでしょうか。      general_qa   \n",
       "15014                              マスターズとは？      general_qa   \n",
       "\n",
       "                                                  output  \n",
       "0      ヴァージン・オーストラリア航空は、2000年8月31日にヴァージン・ブルー航空として、2機の...  \n",
       "1                                              イコクエイラクブカ  \n",
       "2      ラクダは、長時間にわたってエネルギーと水分で満たされた状態を保つために、腰の脂肪を利用しています。  \n",
       "3                                              三女の名前はアリス  \n",
       "4                               小森田友明は1981年7月10日に生まれました。  \n",
       "...                                                  ...  \n",
       "15010                                     変化を受け入れて、違いを見る  \n",
       "15011  レーザーは、電磁波源から光を放出する装置である。  最初のレーザーは、チャールズ・H・タウン...  \n",
       "15012  ロードバイクはアスファルトやセメントの上を走ることを想定して作られており、細いタイヤが装着さ...  \n",
       "15013  不動産投資家は、ビジネスを展開する市場や場所に関する競争力を高めるために、正確で精度の高いロ...  \n",
       "15014  マスターズ・トーナメントは、毎年4月の第1週にジョージア州オーガスタのオーガスタ・ナショナル...  \n",
       "\n",
       "[15015 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file = \"../data/ELYZA-japanese-Llama-2-7b-fast-instruct-q8_0.gguf\"\n",
    "pathlib.Path(model_file).exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_init_cublas: GGML_CUDA_FORCE_MMQ:   no\n",
      "ggml_init_cublas: CUDA_USE_TENSOR_CORES: yes\n",
      "ggml_init_cublas: found 2 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce GTX 1080 Ti, compute capability 6.1, VMM: yes\n",
      "  Device 1: NVIDIA GeForce GTX 1080 Ti, compute capability 6.1, VMM: yes\n",
      "llama_model_loader: loaded meta data with 21 key-value pairs and 291 tensors from ../data/ELYZA-japanese-Llama-2-7b-fast-instruct-q8_0.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = ELYZA-japanese-Llama-2-7b-fast-instruct\n",
      "llama_model_loader: - kv   2:      general.source.huggingface.repository str              = elyza/ELYZA-japanese-Llama-2-7b-fast-...\n",
      "llama_model_loader: - kv   3:                   llama.tensor_data_layout str              = Meta AI original pth\n",
      "llama_model_loader: - kv   4:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   6:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   8:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   9:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  10:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,45043]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,45043]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,45043]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  20:                          general.file_type u32              = 7\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q8_0:  226 tensors\n",
      "llm_load_vocab: mismatch in special tokens definition ( 304/45043 vs 264/45043 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 45043\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
      "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q8_0\n",
      "llm_load_print_meta: model params     = 6.85 B\n",
      "llm_load_print_meta: model size       = 6.77 GiB (8.50 BPW) \n",
      "llm_load_print_meta: general.name     = ELYZA-japanese-Llama-2-7b-fast-instruct\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.33 MiB\n",
      "llm_load_tensors: offloading 16 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 16/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  6936.91 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  1640.75 MiB\n",
      "llm_load_tensors:      CUDA1 buffer size =  1640.75 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:  CUDA_Host KV buffer size =   256.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 36\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =    67.00 MiB\n",
      "llama_new_context_with_model:      CUDA1 compute buffer size =    67.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    95.97 MiB\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<llama_cpp.llama.Llama at 0x7f2765f4f0d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "n_gqa = 8 if \"70b\" in model_file else 1\n",
    "llm = Llama(model_path=model_file, n_gqa=n_gqa, n_gpu_layers=16)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94634082358000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "from peft.utils.peft_types import TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peftの設定は読み込んだモデルをget_peft modelでパラメーターを凍結する際に指定します。\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    ")\n",
    "\n",
    "# creating model\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name_or_path)\n",
    "model = llm\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# # output\n",
    "# \"\"\"\n",
    "# Downloading (…)lve/main/config.json: 100%\n",
    "# 747/747 [00:00<00:00, 59.3kB/s]\n",
    "# Downloading pytorch_model.bin: 100%\n",
    "# 14.1G/14.1G [00:39<00:00, 280MB/s]\n",
    "# trainable params: 3,932,160 || all params: 7,072,948,224 || trainable%: 0.055594355783029126\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # peftの設定は読み込んだモデルをget_peft modelでパラメーターを凍結する際に指定します。\n",
    "# peft_config = PrefixTuningConfig(task_type=TaskType.CAUSAL_LM, num_virtual_tokens=30)\n",
    "#\n",
    "# # creating model\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name_or_path)\n",
    "# model = get_peft_model(model, peft_config)\n",
    "# model.print_trainable_parameters()\n",
    "#\n",
    "# # output\n",
    "# \"\"\"\n",
    "# Downloading (…)lve/main/config.json: 100%\n",
    "# 715/715 [00:00<00:00, 52.6kB/s]\n",
    "# Downloading model.safetensors: 100%\n",
    "# 1.12G/1.12G [00:45<00:00, 28.4MB/s]\n",
    "# trainable params: 1,474,560 || all params: 560,689,152 || trainable%: 0.26299064191632515\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
